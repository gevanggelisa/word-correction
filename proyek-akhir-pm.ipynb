{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"dbnews.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT comment FROM t_comments\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         WKWKWK, GAK SEKALIAN PAK, SELAWAT KE DPR... KA...\n",
       "1         Mantab.. ini br dakwah yg sejati.. kl d tempat...\n",
       "2                                     Salut buat Gus Miftah\n",
       "3         yg nyinyir gak pernah lihat dan baca atw menge...\n",
       "4         Ada adabnya sholawat. Lebih baik ajak ke majel...\n",
       "5         Setiap ulama punya jalan dan cara dakwah masin...\n",
       "6                                   Umpanin nocannya yak...\n",
       "7                            Itulah ceramah yg sebenarnya. \n",
       "8                                   Besok bugil aja selawat\n",
       "9         Bedanya Gus Miftah dengan FPI  / HTI bagaikan ...\n",
       "10        Knp di tempat kerjanya? Mending diundang ke ma...\n",
       "11        nah ini ulama beneran...diterima di semua kala...\n",
       "12        Kerennn.... saya pernah dpt info seperti ini d...\n",
       "13        Hebat Gus.Lanjutkan!inilah makna dakwah sebena...\n",
       "14              Diskotik syariah jadunya nih wkwkwk..mantap\n",
       "15        Niat dan tujuan yg baik pasti mendapat berkah ...\n",
       "16        mantaaapppp..buat di gedung DPR perlu jg kayan...\n",
       "17                           Salut buat owner klub ini.....\n",
       "18                              Josshhh ini baru luar biasa\n",
       "19                   dapat gratisan karena sudah punya nope\n",
       "20        Sebaiknya dimanapun dilakukan batas2 kesopanan...\n",
       "21        Pemandu lagi yang di Manga Besar keknya perlu ...\n",
       "22        JUJUR INI KEREENNNNNNN CARA MENYEBARKAN AGAMA ...\n",
       "23        katimbang alim kemudian jadi maling, menurut s...\n",
       "24        sebenar ulama, mengajak mereka yg masih terses...\n",
       "25                                      Ini namanya apa ya?\n",
       "26        Selamat berjuang Gus,justru tempat seperti itu...\n",
       "27                             Semoga diberikan hidayah..  \n",
       "28        hati hati memviralkan berita yang mengandung i...\n",
       "29        Subhanallah..... semoga mendapatkan hidayah da...\n",
       "                                ...                        \n",
       "598067    Anehnya, dia ngomong itu otomatis menyinggung ...\n",
       "598068    Mas prab... anak TK yg masih balita skrg juga ...\n",
       "598069    Bebas korupsi? Mksdnya keluarganya bebas (utk)...\n",
       "598070    Sy juga bisa baca angka mah, cuma sekolahnya k...\n",
       "598071         Klo cuman tau angka anak SD skrg aja udh tau\n",
       "598072    Jika bisa baca angka mengapa setiap keluar per...\n",
       "598073                       udah sabar aja 2024 coba lagi.\n",
       "598074                        Tapi kok salah terus angkanya\n",
       "598075    Tolong jabarkan harta kekayaan anda yg 1,5 tri...\n",
       "598076                Kebanyakan baca novel wo .Fiksi terus\n",
       "598077    Ponakan saya yg umur 3 th bukan cuma baca angk...\n",
       "598078    Ponakan saya yg umur 3 th bukan cuma baca angk...\n",
       "598079           link nya donk...hoax neh gada link wkwkwkw\n",
       "598080                                  Pacaran jaman nowww\n",
       "598081                                        kapoookkkkkkk\n",
       "598082    Kata2 nya sudah keliatan kok tujuannya, kalo m...\n",
       "598083    Selayaknya lah seorang ulama itu kata-kata nya...\n",
       "598084    Feeling saya mengatakan TGB memenuhi syarat da...\n",
       "598085                                     Kutu loncat ente\n",
       "598086    TGB harus memenangkan Joko, kalau Prabowo mena...\n",
       "598087    Menyejukkan. Bila TGB spt ini trs, sy mau dipi...\n",
       "598088                 Pembangunan yg benar menurut siapa? \n",
       "598089    Kamu membuat ajakan umat muslim bersama orang2...\n",
       "598090            Ne org klo engk mnjilat. Dah d angkut kpk\n",
       "598091    212 nggak pernah ngadain acara beginian ya.......\n",
       "598092    212 nggak pernah ngadain acara beginian ya.......\n",
       "598093             TBG... Sayank.. salah pilih kendraaan..�\n",
       "598094                       Saya bersama TGB pilih Jokowi�\n",
       "598095    Hijrah dari hoax ke non hoax, dari ngawur ke b...\n",
       "598096                       MAJU TERUS 01 !!! %uD83D%uDC4D\n",
       "Name: comment, Length: 598097, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate data\n",
    "data=df.drop_duplicates()\n",
    "#mengubah ke huruf kecil\n",
    "data['comment']=data['comment'].str.lower() \n",
    "#remove non aplabet\n",
    "p = re.compile('[^a-zA-Z]')\n",
    "data['comment'] = [p.sub(' ', x) for x in data['comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wkwkwk  gak sekalian pak  selawat ke dpr    ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mantab   ini br dakwah yg sejati   kl d tempat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salut buat gus miftah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yg nyinyir gak pernah lihat dan baca atw menge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada adabnya sholawat  lebih baik ajak ke majel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setiap ulama punya jalan dan cara dakwah masin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>umpanin nocannya yak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>itulah ceramah yg sebenarnya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>besok bugil aja selawat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bedanya gus miftah dengan fpi    hti bagaikan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knp di tempat kerjanya  mending diundang ke ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nah ini ulama beneran   diterima di semua kala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kerennn     saya pernah dpt info seperti ini d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hebat gus lanjutkan inilah makna dakwah sebena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diskotik syariah jadunya nih wkwkwk  mantap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>niat dan tujuan yg baik pasti mendapat berkah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mantaaapppp  buat di gedung dpr perlu jg kayan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>salut buat owner klub ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>josshhh ini baru luar biasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dapat gratisan karena sudah punya nope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sebaiknya dimanapun dilakukan batas  kesopanan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pemandu lagi yang di manga besar keknya perlu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>jujur ini kereennnnnnn cara menyebarkan agama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>katimbang alim kemudian jadi maling  menurut s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sebenar ulama  mengajak mereka yg masih terses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ini namanya apa ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>selamat berjuang gus justru tempat seperti itu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>semoga diberikan hidayah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hati hati memviralkan berita yang mengandung i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>subhanallah      semoga mendapatkan hidayah da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598063</th>\n",
       "      <td>pertanyaan saya kenapa waktu mertua bapak berk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598064</th>\n",
       "      <td>masa ngerti angka pak  nomor urut pak wowo itu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598066</th>\n",
       "      <td>coba baca al qur an boss    tuntunan dunia akh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598067</th>\n",
       "      <td>anehnya  dia ngomong itu otomatis menyinggung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598068</th>\n",
       "      <td>mas prab    anak tk yg masih balita skrg juga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598069</th>\n",
       "      <td>bebas korupsi  mksdnya keluarganya bebas  utk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598070</th>\n",
       "      <td>sy juga bisa baca angka mah  cuma sekolahnya k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598071</th>\n",
       "      <td>klo cuman tau angka anak sd skrg aja udh tau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598072</th>\n",
       "      <td>jika bisa baca angka mengapa setiap keluar per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598073</th>\n",
       "      <td>udah sabar aja      coba lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598074</th>\n",
       "      <td>tapi kok salah terus angkanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598075</th>\n",
       "      <td>tolong jabarkan harta kekayaan anda yg     tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598076</th>\n",
       "      <td>kebanyakan baca novel wo  fiksi terus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598077</th>\n",
       "      <td>ponakan saya yg umur   th bukan cuma baca angk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598079</th>\n",
       "      <td>link nya donk   hoax neh gada link wkwkwkw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598080</th>\n",
       "      <td>pacaran jaman nowww</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598081</th>\n",
       "      <td>kapoookkkkkkk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598082</th>\n",
       "      <td>kata  nya sudah keliatan kok tujuannya  kalo m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598083</th>\n",
       "      <td>selayaknya lah seorang ulama itu kata kata nya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598084</th>\n",
       "      <td>feeling saya mengatakan tgb memenuhi syarat da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598085</th>\n",
       "      <td>kutu loncat ente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598086</th>\n",
       "      <td>tgb harus memenangkan joko  kalau prabowo mena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598087</th>\n",
       "      <td>menyejukkan  bila tgb spt ini trs  sy mau dipi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598088</th>\n",
       "      <td>pembangunan yg benar menurut siapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598089</th>\n",
       "      <td>kamu membuat ajakan umat muslim bersama orang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598090</th>\n",
       "      <td>ne org klo engk mnjilat  dah d angkut kpk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598091</th>\n",
       "      <td>nggak pernah ngadain acara beginian ya    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598093</th>\n",
       "      <td>tbg    sayank   salah pilih kendraaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598094</th>\n",
       "      <td>saya bersama tgb pilih jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598095</th>\n",
       "      <td>hijrah dari hoax ke non hoax  dari ngawur ke b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584385 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment\n",
       "0       wkwkwk  gak sekalian pak  selawat ke dpr    ka...\n",
       "1       mantab   ini br dakwah yg sejati   kl d tempat...\n",
       "2                                   salut buat gus miftah\n",
       "3       yg nyinyir gak pernah lihat dan baca atw menge...\n",
       "4       ada adabnya sholawat  lebih baik ajak ke majel...\n",
       "5       setiap ulama punya jalan dan cara dakwah masin...\n",
       "6                                 umpanin nocannya yak   \n",
       "7                          itulah ceramah yg sebenarnya  \n",
       "8                                 besok bugil aja selawat\n",
       "9       bedanya gus miftah dengan fpi    hti bagaikan ...\n",
       "10      knp di tempat kerjanya  mending diundang ke ma...\n",
       "11      nah ini ulama beneran   diterima di semua kala...\n",
       "12      kerennn     saya pernah dpt info seperti ini d...\n",
       "13      hebat gus lanjutkan inilah makna dakwah sebena...\n",
       "14            diskotik syariah jadunya nih wkwkwk  mantap\n",
       "15      niat dan tujuan yg baik pasti mendapat berkah ...\n",
       "16      mantaaapppp  buat di gedung dpr perlu jg kayan...\n",
       "17                         salut buat owner klub ini     \n",
       "18                            josshhh ini baru luar biasa\n",
       "19                 dapat gratisan karena sudah punya nope\n",
       "20      sebaiknya dimanapun dilakukan batas  kesopanan...\n",
       "21      pemandu lagi yang di manga besar keknya perlu ...\n",
       "22      jujur ini kereennnnnnn cara menyebarkan agama ...\n",
       "23      katimbang alim kemudian jadi maling  menurut s...\n",
       "24      sebenar ulama  mengajak mereka yg masih terses...\n",
       "25                                    ini namanya apa ya \n",
       "26      selamat berjuang gus justru tempat seperti itu...\n",
       "27                           semoga diberikan hidayah    \n",
       "28      hati hati memviralkan berita yang mengandung i...\n",
       "29      subhanallah      semoga mendapatkan hidayah da...\n",
       "...                                                   ...\n",
       "598063  pertanyaan saya kenapa waktu mertua bapak berk...\n",
       "598064  masa ngerti angka pak  nomor urut pak wowo itu...\n",
       "598066  coba baca al qur an boss    tuntunan dunia akh...\n",
       "598067  anehnya  dia ngomong itu otomatis menyinggung ...\n",
       "598068  mas prab    anak tk yg masih balita skrg juga ...\n",
       "598069  bebas korupsi  mksdnya keluarganya bebas  utk ...\n",
       "598070  sy juga bisa baca angka mah  cuma sekolahnya k...\n",
       "598071       klo cuman tau angka anak sd skrg aja udh tau\n",
       "598072  jika bisa baca angka mengapa setiap keluar per...\n",
       "598073                     udah sabar aja      coba lagi \n",
       "598074                      tapi kok salah terus angkanya\n",
       "598075  tolong jabarkan harta kekayaan anda yg     tri...\n",
       "598076              kebanyakan baca novel wo  fiksi terus\n",
       "598077  ponakan saya yg umur   th bukan cuma baca angk...\n",
       "598079         link nya donk   hoax neh gada link wkwkwkw\n",
       "598080                                pacaran jaman nowww\n",
       "598081                                      kapoookkkkkkk\n",
       "598082  kata  nya sudah keliatan kok tujuannya  kalo m...\n",
       "598083  selayaknya lah seorang ulama itu kata kata nya...\n",
       "598084  feeling saya mengatakan tgb memenuhi syarat da...\n",
       "598085                                   kutu loncat ente\n",
       "598086  tgb harus memenangkan joko  kalau prabowo mena...\n",
       "598087  menyejukkan  bila tgb spt ini trs  sy mau dipi...\n",
       "598088               pembangunan yg benar menurut siapa  \n",
       "598089  kamu membuat ajakan umat muslim bersama orang ...\n",
       "598090          ne org klo engk mnjilat  dah d angkut kpk\n",
       "598091      nggak pernah ngadain acara beginian ya    ...\n",
       "598093           tbg    sayank   salah pilih kendraaan   \n",
       "598094                     saya bersama tgb pilih jokowi \n",
       "598095  hijrah dari hoax ke non hoax  dari ngawur ke b...\n",
       "\n",
       "[584385 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment']=data['comment'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [wkwkwk, gak, sekalian, pak, selawat, ke, dpr,...\n",
       "1         [mantab, ini, br, dakwah, yg, sejati, kl, d, t...\n",
       "2                                [salut, buat, gus, miftah]\n",
       "3         [yg, nyinyir, gak, pernah, lihat, dan, baca, a...\n",
       "4         [ada, adabnya, sholawat, lebih, baik, ajak, ke...\n",
       "5         [setiap, ulama, punya, jalan, dan, cara, dakwa...\n",
       "6                                  [umpanin, nocannya, yak]\n",
       "7                         [itulah, ceramah, yg, sebenarnya]\n",
       "8                              [besok, bugil, aja, selawat]\n",
       "9         [bedanya, gus, miftah, dengan, fpi, hti, bagai...\n",
       "10        [knp, di, tempat, kerjanya, mending, diundang,...\n",
       "11        [nah, ini, ulama, beneran, diterima, di, semua...\n",
       "12        [kerennn, saya, pernah, dpt, info, seperti, in...\n",
       "13        [hebat, gus, lanjutkan, inilah, makna, dakwah,...\n",
       "14        [diskotik, syariah, jadunya, nih, wkwkwk, mantap]\n",
       "15        [niat, dan, tujuan, yg, baik, pasti, mendapat,...\n",
       "16        [mantaaapppp, buat, di, gedung, dpr, perlu, jg...\n",
       "17                          [salut, buat, owner, klub, ini]\n",
       "18                        [josshhh, ini, baru, luar, biasa]\n",
       "19            [dapat, gratisan, karena, sudah, punya, nope]\n",
       "20        [sebaiknya, dimanapun, dilakukan, batas, kesop...\n",
       "21        [pemandu, lagi, yang, di, manga, besar, keknya...\n",
       "22        [jujur, ini, kereennnnnnn, cara, menyebarkan, ...\n",
       "23        [katimbang, alim, kemudian, jadi, maling, menu...\n",
       "24        [sebenar, ulama, mengajak, mereka, yg, masih, ...\n",
       "25                                  [ini, namanya, apa, ya]\n",
       "26        [selamat, berjuang, gus, justru, tempat, seper...\n",
       "27                             [semoga, diberikan, hidayah]\n",
       "28        [hati, hati, memviralkan, berita, yang, mengan...\n",
       "29        [subhanallah, semoga, mendapatkan, hidayah, da...\n",
       "                                ...                        \n",
       "598063    [pertanyaan, saya, kenapa, waktu, mertua, bapa...\n",
       "598064    [masa, ngerti, angka, pak, nomor, urut, pak, w...\n",
       "598066    [coba, baca, al, qur, an, boss, tuntunan, duni...\n",
       "598067    [anehnya, dia, ngomong, itu, otomatis, menying...\n",
       "598068    [mas, prab, anak, tk, yg, masih, balita, skrg,...\n",
       "598069    [bebas, korupsi, mksdnya, keluarganya, bebas, ...\n",
       "598070    [sy, juga, bisa, baca, angka, mah, cuma, sekol...\n",
       "598071    [klo, cuman, tau, angka, anak, sd, skrg, aja, ...\n",
       "598072    [jika, bisa, baca, angka, mengapa, setiap, kel...\n",
       "598073                       [udah, sabar, aja, coba, lagi]\n",
       "598074                  [tapi, kok, salah, terus, angkanya]\n",
       "598075    [tolong, jabarkan, harta, kekayaan, anda, yg, ...\n",
       "598076          [kebanyakan, baca, novel, wo, fiksi, terus]\n",
       "598077    [ponakan, saya, yg, umur, th, bukan, cuma, bac...\n",
       "598079    [link, nya, donk, hoax, neh, gada, link, wkwkwkw]\n",
       "598080                              [pacaran, jaman, nowww]\n",
       "598081                                      [kapoookkkkkkk]\n",
       "598082    [kata, nya, sudah, keliatan, kok, tujuannya, k...\n",
       "598083    [selayaknya, lah, seorang, ulama, itu, kata, k...\n",
       "598084    [feeling, saya, mengatakan, tgb, memenuhi, sya...\n",
       "598085                                 [kutu, loncat, ente]\n",
       "598086    [tgb, harus, memenangkan, joko, kalau, prabowo...\n",
       "598087    [menyejukkan, bila, tgb, spt, ini, trs, sy, ma...\n",
       "598088             [pembangunan, yg, benar, menurut, siapa]\n",
       "598089    [kamu, membuat, ajakan, umat, muslim, bersama,...\n",
       "598090    [ne, org, klo, engk, mnjilat, dah, d, angkut, ...\n",
       "598091    [nggak, pernah, ngadain, acara, beginian, ya, ...\n",
       "598093               [tbg, sayank, salah, pilih, kendraaan]\n",
       "598094                  [saya, bersama, tgb, pilih, jokowi]\n",
       "598095    [hijrah, dari, hoax, ke, non, hoax, dari, ngaw...\n",
       "Name: comment, Length: 584385, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = StemmerFactory()\n",
    "stemmer = db.create_stemmer()\n",
    "\n",
    "data['comment']=data['comment'].apply(lambda x : [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wkwkwk, gak, sekali, pak, selawat, ke, dpr, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mantab, ini, br, dakwah, yg, sejati, kl, d, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[salut, buat, gus, miftah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[yg, nyinyir, gak, pernah, lihat, dan, baca, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ada, adab, sholawat, lebih, baik, ajak, ke, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment\n",
       "0  [wkwkwk, gak, sekali, pak, selawat, ke, dpr, k...\n",
       "1  [mantab, ini, br, dakwah, yg, sejati, kl, d, t...\n",
       "2                         [salut, buat, gus, miftah]\n",
       "3  [yg, nyinyir, gak, pernah, lihat, dan, baca, a...\n",
       "4  [ada, adab, sholawat, lebih, baik, ajak, ke, m..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords.extend([\"yg\", \"dg\", \"dgn\", \"ny\", \"d\", \"dh\", 'atw', 'klo', \n",
    "                       'kalo', 'kl', 'amp', 'biar', 'bikin', 'bilang', \n",
    "                       'gak', 'ga', 'g', 'krn', 'nya', 'nih', 'sih', \n",
    "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', 'dr',\n",
    "                       'jd', 'jgn','sdh', 'aja', 'ya', 'n', 't', 'nggak',\n",
    "                       'hehe', 'wkwkwk', 'pen', 'u', 'nan', 'loh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = set(list_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(words):\n",
    "    return [word for word in words if not word in list_stopwords]\n",
    "\n",
    "data['comment'] = data['comment'].apply(stopwords_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang=pd.read_csv(\"colloquial-indonesian-lexicon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang=slang.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slang</th>\n",
       "      <th>formal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woww</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aminn</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>met</td>\n",
       "      <td>selamat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>netaas</td>\n",
       "      <td>menetas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>keberpa</td>\n",
       "      <td>keberapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eeeehhhh</td>\n",
       "      <td>eh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kata2nyaaa</td>\n",
       "      <td>kata-katanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hallo</td>\n",
       "      <td>halo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kaka</td>\n",
       "      <td>kakak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ka</td>\n",
       "      <td>kak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>daah</td>\n",
       "      <td>dah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aaaaahhhh</td>\n",
       "      <td>ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yaa</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>smga</td>\n",
       "      <td>semoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>slalu</td>\n",
       "      <td>selalu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>amiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kk</td>\n",
       "      <td>kakak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trus</td>\n",
       "      <td>terus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kk</td>\n",
       "      <td>kakak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sii</td>\n",
       "      <td>sih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nyenengin</td>\n",
       "      <td>menyenangkan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bgt</td>\n",
       "      <td>banget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gemess</td>\n",
       "      <td>gemas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>akuuu</td>\n",
       "      <td>aku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jgn</td>\n",
       "      <td>jangan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>yaa</td>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>udah</td>\n",
       "      <td>sudah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gitu</td>\n",
       "      <td>begitu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aja</td>\n",
       "      <td>saja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gemesiin</td>\n",
       "      <td>menggemaskan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>kl</td>\n",
       "      <td>kalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>sich</td>\n",
       "      <td>sih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>pgn</td>\n",
       "      <td>pengin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>senang2</td>\n",
       "      <td>senang-senang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>jh</td>\n",
       "      <td>saja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>seh</td>\n",
       "      <td>sih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>nggak</td>\n",
       "      <td>enggak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>kereeennnn</td>\n",
       "      <td>keren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>donk</td>\n",
       "      <td>dong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>bln</td>\n",
       "      <td>bulan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>gmn</td>\n",
       "      <td>bagaimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>gilakkk</td>\n",
       "      <td>gila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>gtu2</td>\n",
       "      <td>begitu-gitu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>sehh</td>\n",
       "      <td>sih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>kakk</td>\n",
       "      <td>kak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>ajah</td>\n",
       "      <td>saja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>cpet</td>\n",
       "      <td>cepat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>bnget</td>\n",
       "      <td>banget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>aq</td>\n",
       "      <td>aku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>uda</td>\n",
       "      <td>sudah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>nyobain</td>\n",
       "      <td>mencoba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>dlm</td>\n",
       "      <td>dalam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>wktu</td>\n",
       "      <td>waktu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>hr</td>\n",
       "      <td>hari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>gatau</td>\n",
       "      <td>enggak tau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15001</th>\n",
       "      <td>gataunya</td>\n",
       "      <td>enggak taunya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15002</th>\n",
       "      <td>gtau</td>\n",
       "      <td>enggak tau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>gatau</td>\n",
       "      <td>enggak tau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15004</th>\n",
       "      <td>fans2</td>\n",
       "      <td>fan-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>gaharus</td>\n",
       "      <td>enggak harus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15006 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            slang         formal\n",
       "0            woww            wow\n",
       "1           aminn           amin\n",
       "2             met        selamat\n",
       "3          netaas        menetas\n",
       "4         keberpa       keberapa\n",
       "5        eeeehhhh             eh\n",
       "6      kata2nyaaa   kata-katanya\n",
       "7           hallo           halo\n",
       "8            kaka          kakak\n",
       "9              ka            kak\n",
       "10           daah            dah\n",
       "11      aaaaahhhh             ah\n",
       "12            yaa             ya\n",
       "13           smga         semoga\n",
       "14          slalu         selalu\n",
       "15          amiin           amin\n",
       "16             kk          kakak\n",
       "17           trus          terus\n",
       "18             kk          kakak\n",
       "19            sii            sih\n",
       "20      nyenengin   menyenangkan\n",
       "21            bgt         banget\n",
       "22         gemess          gemas\n",
       "23          akuuu            aku\n",
       "24            jgn         jangan\n",
       "25            yaa             ya\n",
       "26           udah          sudah\n",
       "27           gitu         begitu\n",
       "28            aja           saja\n",
       "29       gemesiin   menggemaskan\n",
       "...           ...            ...\n",
       "14976          kl           kalo\n",
       "14977        sich            sih\n",
       "14978         pgn         pengin\n",
       "14979     senang2  senang-senang\n",
       "14980          jh           saja\n",
       "14981         seh            sih\n",
       "14982       nggak         enggak\n",
       "14983  kereeennnn          keren\n",
       "14984        donk           dong\n",
       "14985         bln          bulan\n",
       "14986         gmn      bagaimana\n",
       "14987     gilakkk           gila\n",
       "14988        gtu2    begitu-gitu\n",
       "14989        sehh            sih\n",
       "14990        kakk            kak\n",
       "14991        ajah           saja\n",
       "14992        cpet          cepat\n",
       "14993       bnget         banget\n",
       "14994          aq            aku\n",
       "14995         uda          sudah\n",
       "14996     nyobain        mencoba\n",
       "14997         dlm          dalam\n",
       "14998        wktu          waktu\n",
       "14999          hr           hari\n",
       "15000       gatau     enggak tau\n",
       "15001    gataunya  enggak taunya\n",
       "15002        gtau     enggak tau\n",
       "15003       gatau     enggak tau\n",
       "15004       fans2        fan-fan\n",
       "15005     gaharus   enggak harus\n",
       "\n",
       "[15006 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizad_word_dict = {}\n",
    "\n",
    "for index, row in slang.iterrows():\n",
    "    if row[0] not in normalizad_word_dict:\n",
    "        normalizad_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "\n",
    "data['comment'] = data['comment'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wkwkwk, enggak, sekali, pak, selawat, ke, dpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mantab, ini, baru, dakwah, yang, sejati, kala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[salut, buat, gus, miftah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[yang, nyinyir, enggak, pernah, lihat, dan, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ada, adab, sholawat, lebih, baik, ajak, ke, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[tiap, ulama, punya, jalan, dan, cara, dakwah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[umpanin, nocannya, ya]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[itu, ceramah, yang, benar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[besok, bugil, saja, selawat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[beda, gus, miftah, dengan, fpi, hti, bagai, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[kenapa, di, tempat, kerja, mending, undang, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[nah, ini, ulama, benaran, terima, di, semua, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[keren, saya, pernah, dapat, info, seperti, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[hebat, gus, lanjut, ini, makna, dakwah, benar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[diskotik, syariah, jadunya, nih, wkwkwk, mantap]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[niat, dan, tuju, yang, baik, pasti, dapat, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[mantaaapppp, buat, di, gedung, dpr, perlu, ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[salut, buat, owner, klub, ini]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[josshhh, ini, baru, luar, biasa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[dapat, gratis, karena, sudah, punya, nope]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[baik, mana, laku, batas, sopan, tetap, harus,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[pandu, lagi, yang, di, manga, besar, kayak, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[jujur, ini, kereennnnnnn, cara, sebar, agama,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[katimbang, alim, kemudian, jadi, maling, turu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[benar, ulama, ajak, mereka, yang, masih, sesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[ini, nama, apa, ya]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[selamat, juang, gus, justru, tempat, seperti,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[moga, beri, hidayah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[hati, hati, memviralkan, berita, yang, kandun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[subhanallah, moga, dapat, hidayah, dari, alla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[selamat, nikmat, hukum, dunia, atas, prilaku,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[dasar, preman, enggak, tanggung, jawab, kok, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[orang, grindong, enggak, akan, ngomentari, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>[ayo, gerombol, kok, enggak, ada, yang, koment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>[sik, asik, selamat, nikmat, hotel, prodeo, ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>[buni, yaniiii, mana, anda, kejaaarr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>[wowo, enggak, sekali]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[jangan, tangkap, pimrednya, doang, tangkap, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[walaupun, cuma, tahun, ente, sudah, dapat, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>[gantung, az]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>[sekali, buni, yani, biar, adil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[kirim, ke, kamar, bonita, bonita, itu, nama, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>[gua, paling, senang, lihat, beginian, buron, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>[tungguin, saja, nih, bentar, lagi, kubu, prab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[karena, kabur, tambahkan, ya, hukum, nya]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[ini, kabar, bagus, yang, boleh, dengar, hari,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[telat, kabur, tong, kaciann]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[mencari, duit, dari, nyebar, fitnah, duit, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[moga, bahagia, di, rumah, yang, baru]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[periksa, bank, account, nya, atau, bank, acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[moga, bisa, ajar, untuk, tidak, cari, nafkah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[suntik, mati]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[sikat, semua, orang, orang, acau, negeri, dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[habisin, saja, jok, orang, yang, gangu, lu, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[menunggu, buni, yani, kapan, tangkap, padahal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[kok, cuma, tahun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[laaaahhh, bukan, kata, nasbung, pemred, obor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[kapan, buni, yani]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[sip, tinggal, yang, kabur, umroh, enggak, bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[yang, model, beginian, main, fitnah, sih, mes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment\n",
       "0   [wkwkwk, enggak, sekali, pak, selawat, ke, dpr...\n",
       "1   [mantab, ini, baru, dakwah, yang, sejati, kala...\n",
       "2                          [salut, buat, gus, miftah]\n",
       "3   [yang, nyinyir, enggak, pernah, lihat, dan, ba...\n",
       "4   [ada, adab, sholawat, lebih, baik, ajak, ke, m...\n",
       "5   [tiap, ulama, punya, jalan, dan, cara, dakwah,...\n",
       "6                             [umpanin, nocannya, ya]\n",
       "7                         [itu, ceramah, yang, benar]\n",
       "8                       [besok, bugil, saja, selawat]\n",
       "9   [beda, gus, miftah, dengan, fpi, hti, bagai, s...\n",
       "10  [kenapa, di, tempat, kerja, mending, undang, k...\n",
       "11  [nah, ini, ulama, benaran, terima, di, semua, ...\n",
       "12  [keren, saya, pernah, dapat, info, seperti, in...\n",
       "13  [hebat, gus, lanjut, ini, makna, dakwah, benar...\n",
       "14  [diskotik, syariah, jadunya, nih, wkwkwk, mantap]\n",
       "15  [niat, dan, tuju, yang, baik, pasti, dapat, be...\n",
       "16  [mantaaapppp, buat, di, gedung, dpr, perlu, ju...\n",
       "17                    [salut, buat, owner, klub, ini]\n",
       "18                  [josshhh, ini, baru, luar, biasa]\n",
       "19        [dapat, gratis, karena, sudah, punya, nope]\n",
       "20  [baik, mana, laku, batas, sopan, tetap, harus,...\n",
       "21  [pandu, lagi, yang, di, manga, besar, kayak, p...\n",
       "22  [jujur, ini, kereennnnnnn, cara, sebar, agama,...\n",
       "23  [katimbang, alim, kemudian, jadi, maling, turu...\n",
       "24  [benar, ulama, ajak, mereka, yang, masih, sesa...\n",
       "25                               [ini, nama, apa, ya]\n",
       "26  [selamat, juang, gus, justru, tempat, seperti,...\n",
       "27                              [moga, beri, hidayah]\n",
       "28  [hati, hati, memviralkan, berita, yang, kandun...\n",
       "29  [subhanallah, moga, dapat, hidayah, dari, alla...\n",
       "..                                                ...\n",
       "70  [selamat, nikmat, hukum, dunia, atas, prilaku,...\n",
       "71  [dasar, preman, enggak, tanggung, jawab, kok, ...\n",
       "72  [orang, grindong, enggak, akan, ngomentari, be...\n",
       "73  [ayo, gerombol, kok, enggak, ada, yang, koment...\n",
       "74  [sik, asik, selamat, nikmat, hotel, prodeo, ka...\n",
       "75              [buni, yaniiii, mana, anda, kejaaarr]\n",
       "76                             [wowo, enggak, sekali]\n",
       "77  [jangan, tangkap, pimrednya, doang, tangkap, s...\n",
       "78  [walaupun, cuma, tahun, ente, sudah, dapat, ge...\n",
       "79                                      [gantung, az]\n",
       "80                   [sekali, buni, yani, biar, adil]\n",
       "81  [kirim, ke, kamar, bonita, bonita, itu, nama, ...\n",
       "82  [gua, paling, senang, lihat, beginian, buron, ...\n",
       "83  [tungguin, saja, nih, bentar, lagi, kubu, prab...\n",
       "84         [karena, kabur, tambahkan, ya, hukum, nya]\n",
       "85  [ini, kabar, bagus, yang, boleh, dengar, hari,...\n",
       "86                      [telat, kabur, tong, kaciann]\n",
       "87  [mencari, duit, dari, nyebar, fitnah, duit, bu...\n",
       "88             [moga, bahagia, di, rumah, yang, baru]\n",
       "89  [periksa, bank, account, nya, atau, bank, acco...\n",
       "90  [moga, bisa, ajar, untuk, tidak, cari, nafkah,...\n",
       "91                                     [suntik, mati]\n",
       "92  [sikat, semua, orang, orang, acau, negeri, dem...\n",
       "93  [habisin, saja, jok, orang, yang, gangu, lu, j...\n",
       "94  [menunggu, buni, yani, kapan, tangkap, padahal...\n",
       "95                                 [kok, cuma, tahun]\n",
       "96  [laaaahhh, bukan, kata, nasbung, pemred, obor,...\n",
       "97                                [kapan, buni, yani]\n",
       "98  [sip, tinggal, yang, kabur, umroh, enggak, bal...\n",
       "99  [yang, model, beginian, main, fitnah, sih, mes...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1268: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected %s; aliasing chunkize to chunkize_serial\" % entity)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "wiki = WikiCorpus('idwiki-latest-pages-articles.xml.bz2', lemmatize=False, dictionary={})\n",
    "sentences = list(wiki.get_texts())\n",
    "params = {'size': 200, 'window': 10, 'min_count': 10, \n",
    "          'workers': max(1, multiprocessing.cpu_count() - 1), 'sample': 1E-3,}\n",
    "word2vec = Word2Vec(sentences, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-46b3f66d2554>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[0;32m    598\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m             seed=seed, hs=hs, negative=negative, cbow_mean=cbow_mean, min_alpha=min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[0;32m    750\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             **kwargs)\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             total_words=total_words, **kwargs)\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[1;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# should be set by `build_vocab`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "Word2Vec(\"Sy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj_Addr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Adj_Addr'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-54baa42043b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# apply the function above to your text data and create a new column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'replaced_words'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Adj_Addr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplace_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Adj_Addr'"
     ]
    }
   ],
   "source": [
    "threshold = 0.6 # define a threshold\n",
    "similar_words = {word:{} for word in data} # create a dictionary from root_words\n",
    "for word in data:\n",
    "    \"\"\"        \n",
    "    Loop over all words in root_words and create\n",
    "    a temp dict with values above the threshold using the\n",
    "    model.most_similar() method\n",
    "    \"\"\"\n",
    "    temp_dict = dict(word2vec.most_similar(word))\n",
    "    temp_dict = {k:v for k,v in temp_dict.items() if v > threshold}\n",
    "    # append the temp dict to the similar_words dict\n",
    "    similar_words[word] = temp_dict\n",
    "\n",
    "\n",
    "def replace_words(text):\n",
    "    \"\"\"\n",
    "    1.Loop over every word in the text (text is one row in the data \n",
    "    2.If the word is in root_words, simply append it to temp_text\n",
    "    3.If not, then loop over all words in the similar_words dict, and\n",
    "    check if the current word is in one of the sub dictionaries - if so,\n",
    "    append the root_word to the temp_text\n",
    "    4. Use the flags so we don't miss out on any words (e.g. there\n",
    "    may be words that are not in the root_words list or in the\n",
    "    similar_words sub dictionaries\n",
    "    5. Return temp_text\n",
    "    \"\"\"\n",
    "    temp_text = []\n",
    "    for word in text:\n",
    "        in_root_words_flag = False\n",
    "        found_root_flag = False\n",
    "\n",
    "        if word in root_words:\n",
    "            temp_text.append(word)\n",
    "            in_root_words_flag = True\n",
    "\n",
    "        else:\n",
    "            for root_word in similar_words:\n",
    "                if word in similar_words[root_word]:\n",
    "                    temp_text.append(root_word)\n",
    "                    found_root_flag = True\n",
    "\n",
    "        if in_root_words_flag == False and found_root_flag == False:\n",
    "            temp_text.append(word)\n",
    "\n",
    "    return temp_text\n",
    "\n",
    "# apply the function above to your text data and create a new column\n",
    "data['replaced_words'] = data[\"Adj_Addr\"].get.apply(replace_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
